{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the abs path of \"../model_merging\"\n",
    "abs_path = os.path.abspath(\"../model_merging\")\n",
    "if abs_path not in sys.path:\n",
    "    sys.path.append(abs_path)\n",
    "os.chdir(abs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Script for actually merging models.\"\"\"\n",
    "import os\n",
    "\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from model_merging import data\n",
    "from model_merging import evaluation\n",
    "from model_merging import hdf5_util\n",
    "from model_merging import merging\n",
    "\n",
    "\n",
    "def load_models(models, from_pt):\n",
    "    output_models = []\n",
    "    for i, model_str in enumerate(models):\n",
    "        model_str = os.path.expanduser(model_str)\n",
    "        model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "            model_str, from_pt=from_pt\n",
    "        )\n",
    "        output_models.append(model)\n",
    "        if i == 0:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_str)\n",
    "    return output_models, tokenizer\n",
    "\n",
    "\n",
    "def load_fishers(fishers):\n",
    "    if not fishers:\n",
    "        return None\n",
    "    fishers = []\n",
    "    for fisher_str in fishers:\n",
    "        fisher_str = os.path.expanduser(fisher_str)\n",
    "        fisher = hdf5_util.load_variables_from_hdf5(fisher_str, trainable=False)\n",
    "        fishers.append(fisher)\n",
    "    return fishers\n",
    "\n",
    "\n",
    "def get_coeffs_set(models, coeff_mode, n_coeffs):\n",
    "    n_models = len(models)\n",
    "    if coeff_mode == \"grid\":\n",
    "        assert n_models == 2\n",
    "        return merging.create_pairwise_grid_coeffs(n_coeffs)\n",
    "    elif coeff_mode == \"random\":\n",
    "        return merging.create_random_coeffs(n_models, n_coeffs)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "def get_best_results(results):\n",
    "    return max(results, key=lambda r: evaluation.average_score(r.score))\n",
    "\n",
    "# flags.DEFINE_integer(\"n_examples\", 4096, \"\")\n",
    "# flags.DEFINE_integer(\"batch_size\", 32, \"\")\n",
    "# flags.DEFINE_integer(\"sequence_length\", 128, \"\")\n",
    "\n",
    "# flags.DEFINE_integer(\"n_coeffs\", 51, \"\")\n",
    "# flags.DEFINE_enum(\"coeff_mode\", \"grid\", [\"grid\", \"random\"], \"\")\n",
    "\n",
    "# flags.DEFINE_float(\"fisher_floor\", 1e-6, \"\")\n",
    "# flags.DEFINE_bool(\"favor_target_model\", True, \"\")\n",
    "# flags.DEFINE_bool(\"normalize_fishers\", True, \"\")\n",
    "def merge_and_evaluate(\n",
    "    models,\n",
    "    fishers,\n",
    "    glue_task,\n",
    "    split=\"validation\",\n",
    "    from_pt=True,\n",
    "    n_examples=4096,\n",
    "    batch_size=32,\n",
    "    sequence_length=128,\n",
    "    fisher_floor=1e-6,\n",
    "    favor_target_model=True,\n",
    "    normalize_fishers=True,\n",
    "    coeff_mode=\"grid\",\n",
    "    n_coeffs=51,\n",
    "):\n",
    "    if fishers:\n",
    "        assert len(fishers) == len(models)\n",
    "\n",
    "    models, tokenizer = load_models(models, from_pt)\n",
    "\n",
    "    fishers = load_fishers(fishers)\n",
    "\n",
    "    ds = data.load_glue_dataset(\n",
    "        task=glue_task,\n",
    "        split=split,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=sequence_length,\n",
    "    )\n",
    "    ds = ds.take(n_examples).batch(batch_size)\n",
    "\n",
    "    metric = evaluation.load_metric_for_glue_task(glue_task)\n",
    "\n",
    "    coefficients_set = get_coeffs_set(models, coeff_mode, n_coeffs)\n",
    "\n",
    "    results = merging.merging_coefficients_search(\n",
    "        models,\n",
    "        coefficients_set=coefficients_set,\n",
    "        dataset=ds,\n",
    "        metric=metric,\n",
    "        fishers=fishers,\n",
    "        fisher_floor=fisher_floor,\n",
    "        favor_target_model=favor_target_model,\n",
    "        normalize_fishers=normalize_fishers,\n",
    "    )\n",
    "\n",
    "    best = get_best_results(results)\n",
    "    print(80 * \"*\")\n",
    "    print(\" Best Merge\")\n",
    "    print(80 * \"*\")\n",
    "    merging.print_merge_result(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2ForSequenceClassification: ['transformer.h.11.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.7.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2ForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2ForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2ForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2ForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2ForSequenceClassification: ['transformer.h.11.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.7.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2ForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2ForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2ForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2ForSequenceClassification for predictions without further training.\n",
      "/Users/briancruz/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [768,2] != values[1].shape = [768,3] [Op:Pack] name: packed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# EVAL_TASK=rte\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# # Using PavanNeerudu/gpt2-finetuned-mnli doesn't work b/c of tokenizer issues\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#     --glue_task=$EVAL_TASK \\\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#     --n_examples=100\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m merge_and_evaluate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     models\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m../data/gpt2-finetuned-rte-fixed\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m../data/gpt2-finetuned-mnli-fixed\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     fishers\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     glue_task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrte\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     n_examples\u001b[39m=\u001b[39;49m\u001b[39m4096\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     sequence_length\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     fisher_floor\u001b[39m=\u001b[39;49m\u001b[39m1e-6\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     favor_target_model\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     normalize_fishers\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m metric \u001b[39m=\u001b[39m evaluation\u001b[39m.\u001b[39mload_metric_for_glue_task(glue_task)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m coefficients_set \u001b[39m=\u001b[39m get_coeffs_set(models, coeff_mode, n_coeffs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m results \u001b[39m=\u001b[39m merging\u001b[39m.\u001b[39;49mmerging_coefficients_search(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     models,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     coefficients_set\u001b[39m=\u001b[39;49mcoefficients_set,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     dataset\u001b[39m=\u001b[39;49mds,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     fishers\u001b[39m=\u001b[39;49mfishers,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     fisher_floor\u001b[39m=\u001b[39;49mfisher_floor,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     favor_target_model\u001b[39m=\u001b[39;49mfavor_target_model,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     normalize_fishers\u001b[39m=\u001b[39;49mnormalize_fishers,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m best \u001b[39m=\u001b[39m get_best_results(results)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/briancruz/2023-fall-cs-194-294-merging-llms/notebooks/explore_merge.ipynb#W2sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m80\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/merging.py:137\u001b[0m, in \u001b[0;36mmerging_coefficients_search\u001b[0;34m(mergeable_models, coefficients_set, dataset, metric, fishers, fisher_floor, favor_target_model, normalize_fishers, print_results)\u001b[0m\n\u001b[1;32m    128\u001b[0m merged_models \u001b[39m=\u001b[39m generate_merged_for_coeffs_set(\n\u001b[1;32m    129\u001b[0m     mergeable_models,\n\u001b[1;32m    130\u001b[0m     coefficients_set,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     normalize_fishers\u001b[39m=\u001b[39mnormalize_fishers,\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    136\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 137\u001b[0m \u001b[39mfor\u001b[39;00m coeffs, merged_model \u001b[39min\u001b[39;00m merged_models:\n\u001b[1;32m    138\u001b[0m     score \u001b[39m=\u001b[39m evaluation\u001b[39m.\u001b[39mevaluate_model(merged_model, dataset, metric)\n\u001b[1;32m    139\u001b[0m     result \u001b[39m=\u001b[39m MergeResult(coefficients\u001b[39m=\u001b[39mcoeffs, score\u001b[39m=\u001b[39mscore)\n",
      "File \u001b[0;32m~/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/merging.py:105\u001b[0m, in \u001b[0;36mgenerate_merged_for_coeffs_set\u001b[0;34m(mergeable_models, coefficients_set, fishers, fisher_floor, favor_target_model, normalize_fishers)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m({\u001b[39mlen\u001b[39m(output_variables)} \u001b[39m|\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mlen\u001b[39m(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m variables_to_merge)) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[39mfor\u001b[39;00m coefficients \u001b[39min\u001b[39;00m coefficients_set:\n\u001b[0;32m--> 105\u001b[0m     _merge_with_coeffs(\n\u001b[1;32m    106\u001b[0m         output_variables,\n\u001b[1;32m    107\u001b[0m         variables_to_merge,\n\u001b[1;32m    108\u001b[0m         coefficients\u001b[39m=\u001b[39;49mcoefficients,\n\u001b[1;32m    109\u001b[0m         fishers\u001b[39m=\u001b[39;49mfishers,\n\u001b[1;32m    110\u001b[0m         fisher_floor\u001b[39m=\u001b[39;49mfisher_floor,\n\u001b[1;32m    111\u001b[0m         favor_target_model\u001b[39m=\u001b[39;49mfavor_target_model,\n\u001b[1;32m    112\u001b[0m         normalization_constants\u001b[39m=\u001b[39;49mnorm_constants,\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m     \u001b[39myield\u001b[39;00m coefficients, output_model\n",
      "File \u001b[0;32m~/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/merging.py:69\u001b[0m, in \u001b[0;36m_merge_with_coeffs\u001b[0;34m(output_variables, variables_to_merge, coefficients, fishers, fisher_floor, favor_target_model, normalization_constants)\u001b[0m\n\u001b[1;32m     67\u001b[0m     lhs\u001b[39m.\u001b[39mappend(tmp)\n\u001b[1;32m     68\u001b[0m     rhs\u001b[39m.\u001b[39mappend(tmp \u001b[39m*\u001b[39m mvar)\n\u001b[0;32m---> 69\u001b[0m rhs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mreduce_sum(rhs, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     70\u001b[0m lhs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_sum(lhs, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     71\u001b[0m var\u001b[39m.\u001b[39massign(rhs \u001b[39m/\u001b[39m lhs)\n",
      "File \u001b[0;32m~/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   6655\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 6656\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [768,2] != values[1].shape = [768,3] [Op:Pack] name: packed"
     ]
    }
   ],
   "source": [
    "# EVAL_TASK=rte\n",
    "\n",
    "# # Using PavanNeerudu/gpt2-finetuned-mnli doesn't work b/c of tokenizer issues\n",
    "# # RTE_MODEL=PavanNeerudu/gpt2-finetuned-rte\n",
    "# # MNLI_MODEL=PavanNeerudu/gpt2-finetuned-mnli\n",
    "\n",
    "# # We need to fix the tokenizer issues locally to get this to work\n",
    "# # Relative to the model_merging directory\n",
    "# RTE_MODEL=../data/gpt2-finetuned-rte-fixed\n",
    "# MNLI_MODEL=../data/gpt2-finetuned-mnli-fixed\n",
    "\n",
    "# # Isometric merge.\n",
    "# python3 ./scripts/merge_and_evaluate.py  \\\n",
    "#     --models=$RTE_MODEL,$MNLI_MODEL \\\n",
    "#     --glue_task=$EVAL_TASK \\\n",
    "#     --n_examples=100\n",
    "\n",
    "merge_and_evaluate(\n",
    "    models=[\"../data/gpt2-finetuned-rte-fixed\", \"../data/gpt2-finetuned-mnli-fixed\"],\n",
    "    fishers=None,\n",
    "    glue_task=\"rte\",\n",
    "    split=\"validation\",\n",
    "    n_examples=4096,\n",
    "    batch_size=32,\n",
    "    sequence_length=128,\n",
    "    fisher_floor=1e-6,\n",
    "    favor_target_model=True,\n",
    "    normalize_fishers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
