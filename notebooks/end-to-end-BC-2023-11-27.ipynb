{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end notebook!\n",
    "\n",
    "Here is the workflow:\n",
    "* Sampling configs (sampling parameters, etc.) lead to...\n",
    "* Weaving configs (blank model settings, donor model settings, layer assignments) lead to...\n",
    "* Models (probably TFRobertaForSequenceClassification in all cases) lead to...\n",
    "* Performance scores (numbers from 0-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: visions 0.7.5 does not provide the extra 'type-image-path'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "\n",
    "! pip install -q joblib  # joblib for memoizing functions\n",
    "! pip install -q ipywidgets widgetsnbextension pandas-profiling # IProgress for progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model_merging to the python path\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "model_merging_base = os.path.abspath(\"../model_merging/\")\n",
    "# assert it exist\n",
    "assert os.path.exists(model_merging_base)\n",
    "if model_merging_base not in sys.path:\n",
    "    sys.path.append(model_merging_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib for caching and distributed computing\n",
    "from math import sqrt\n",
    "\n",
    "from joblib import Memory, Parallel, delayed\n",
    "\n",
    "memory = Memory(location=\"cache\", verbose=10)\n",
    "\n",
    "parallel = Parallel(n_jobs=2, return_as=\"generator\")\n",
    "output_generator = parallel(delayed(sqrt)(i**2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and cached functions\n",
    "\n",
    "import os\n",
    "\n",
    "from llm_weaver import (\n",
    "    calculate_score_from_weaving_config,\n",
    "    test_weaver,\n",
    ")\n",
    "\n",
    "# Disable parallelism in tokenizers to avoid deadlocks\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "calculate_score_from_weaving_config_cached = memory.cache(\n",
    "    calculate_score_from_weaving_config\n",
    ")\n",
    "test_weaver_cached = memory.cache(test_weaver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Test weaving code\n",
    "\n",
    "This test makes sure that our score when using the weaver to reconstruct a model from all its parts get the same evaluation score as the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]: Loading test_weaver from cache/joblib/llm_weaver/test_weaver/10dcf0499632d2dc426a8c51f8748c07\n",
      "_________________________________________test_weaver cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading test_weaver from cache/joblib/llm_weaver/test_weaver/bd08da19319cbff8cce9779ebe451148\n",
      "_________________________________________test_weaver cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'accuracy': 0.7}, {'accuracy': 0.7}),\n",
       " ({'accuracy': 0.3}, {'accuracy': 0.3})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ids = [\n",
    "    \"textattack/roberta-base-RTE\",\n",
    "    \"textattack/roberta-base-MNLI\",\n",
    "]\n",
    "\n",
    "# for model_id in model_ids:\n",
    "#     test_weaver(model_id)\n",
    "\n",
    "# You can run this more than once, and it will pull from the cache on subsequent runs\n",
    "Parallel(n_jobs=2, return_as=\"list\")(\n",
    "    delayed(test_weaver_cached)(model_id) for model_id in model_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps 1-3: configs to graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to sample configs\n",
    "import random\n",
    "\n",
    "from llm_weaver import dict_overwrite, get_model_config\n",
    "\n",
    "\n",
    "def sample_weave_configs_iter(p=0.5, seed=42, max_configs=1):\n",
    "    # set random seed\n",
    "    random.seed(seed)\n",
    "\n",
    "    donor_model_ids = [\n",
    "        \"textattack/roberta-base-RTE\",\n",
    "        \"textattack/roberta-base-MNLI\",\n",
    "    ]\n",
    "    blank_model_config = dict_overwrite(\n",
    "        get_model_config(\"textattack/roberta-base-RTE\"),\n",
    "        {\n",
    "            \"num_hidden_layers\": 12 ,\n",
    "        },\n",
    "    )\n",
    "    for _ in range(max_configs):\n",
    "        config = {\n",
    "            \"glue_task\": \"rte\",\n",
    "            \"tokenizer_model_id\": \"textattack/roberta-base-RTE\",\n",
    "            # The task (i.e. the classification head output size should match the task at hand)\n",
    "            \"blank_model_config\": blank_model_config,\n",
    "            # Layer assignments\n",
    "            \"layer_assignments\": [\n",
    "                {\n",
    "                    \"type\": \"SingleLayer\",\n",
    "                    \"params\": {\n",
    "                        # Load donor model # Choose a random donor model according to the p parameter\n",
    "                        \"donor\": random.choices(donor_model_ids, weights=[p, 1 - p])[0],\n",
    "                        # Pick a layer\n",
    "                        \"hidden_layer_number\": i,\n",
    "                    },\n",
    "                }\n",
    "                for i in range(12)\n",
    "            ],\n",
    "            # The head (i.e. the classification head should match the task at hand)\n",
    "            # THESE ARE DIFFERENT BETWEEN RTE AND MNLI\n",
    "            \"classification_head\": {\n",
    "                \"type\": \"SingleClassificationHead\",\n",
    "                \"params\": {\n",
    "                    \"donor\": \"textattack/roberta-base-RTE\",\n",
    "                },\n",
    "            },\n",
    "            # The embeddings layer\n",
    "            # THESE ARE DIFFERENT BETWEEN RTE AND MNLI\n",
    "            \"embeddings\": {\n",
    "                \"type\": \"SingleEmbeddings\",\n",
    "                \"params\": {\n",
    "                    \"donor\": \"textattack/roberta-base-RTE\",\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "        yield config\n",
    "\n",
    "\n",
    "sample_config = dict(p=0.5, seed=42, max_configs=100)\n",
    "\n",
    "# Generate the sample configs and save to a file just in case\n",
    "weave_configs = list(sample_weave_configs_iter(**sample_config))\n",
    "\n",
    "\n",
    "len(weave_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/7aafface3666fa24d5d007289da33a67\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/00660772bcde78f2d6aea184b3c93a8d\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/de1a309506b751a498c7f7558d603ea6\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/667f71624847b0c3b69b2a87d973b3a1\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/0e44a2e165ab2712fb0329477f283eba\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sample_config_to_plots(sample_config, n_jobs=5):\n",
    "    weave_configs = list(\n",
    "        sample_weave_configs_iter(**sample_config),\n",
    "    )\n",
    "\n",
    "    scores = Parallel(n_jobs=n_jobs, return_as=\"list\")(\n",
    "        delayed(calculate_score_from_weaving_config_cached)(\n",
    "            weave_config,\n",
    "            n_examples=4096,\n",
    "            split=\"validation\",\n",
    "        )\n",
    "        for weave_config in weave_configs\n",
    "    )\n",
    "    accuracies = [score[\"accuracy\"] for score in scores]\n",
    "\n",
    "    title = f\"Accuracy distribution on task {weave_configs[0]['glue_task']} with p={sample_config['p']} with N={len(accuracies)}\"\n",
    "\n",
    "    # create figure and ax\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(accuracies, bins=10)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return accuracies, weave_configs\n",
    "\n",
    "\n",
    "accuracies, weave_configs = sample_config_to_plots(\n",
    "    dict(p=0.5, seed=42, max_configs=5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/667f71624847b0c3b69b2a87d973b3a1\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/de1a309506b751a498c7f7558d603ea6\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/7aafface3666fa24d5d007289da33a67\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/00660772bcde78f2d6aea184b3c93a8d\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/0e44a2e165ab2712fb0329477f283eba\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/e95eccf24ed96cd552255c4c8e0e6e87\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/f011d5f666e8b49aff9b3dfdf24158aa\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/dc1b2852ae29cb3e88668f7884062bbf\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/4524ddeb047d28e3e89277ac32c50605\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/5b23699a1de94c7174612d17dd7e82dc\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/b2bd142ed712454f24f50c22b68f1461\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/3de19ffb31d3bd61d56423ba4b0b6d6b\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/fd8fdd666a149f14315d584ece8851d9\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/a5c7846d23b8e3220789f23feef8e61d\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/1a9a3fb3ffc64b91258777629deb4cbe\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/27b8cbd655417ed61a886fe3e02540b5\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/896db96e9ab035e41ad077ee7d578bed\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/fb6ad992f58abbdee5afd7fa10e1fd99\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/0391d053e486bdd9d9b7a73338445e72\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/746387fffdab518f7d242d72a1e8a6de\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/8efd3b47fb56675098a0d7b1f6eb6427\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/0ebc6a8f86a0ddb89455116d48e328dd\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/cf5260263ae62787a73a3c969ed0c882\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/515c8d6f1f0391f0d545ab7b6e4ba320\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/33a3b47cb59e28f0e2c8094527543fd7\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/865e1e27b59ac3aa10228708d8fef4a5\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/91df58baf3629fe68a322b438c366b02\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/8d9c48325fe3696c44199819de547322[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/30763a0cc77c885419193b7b446e6e7c\n",
      "\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/02e7fb0ac4b39945eaac10cb32542f3d\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/48362a63f3ff4da693f75665fd342a35\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/19f207b54efdab4c0bebb0a54d126397\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/aa5c964c141f0b28a9fecdd729810a91\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/aae6dd15e072527d3034f0e69f1dda02\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/272952a59b286f9b7cd7ab46b547db38\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/196f564c8fca047ed60a78ce3dc18178\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/9f629df20da3ea8b36229b5eb4889611_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/0268b4ac549b8e7cc4048d810306b77b\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/84e17e214149198769ddcc14c080577c\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/0831de63b7c0900bbc905f64fa541969\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/f01169b8214f0597a8b54d13e7d0e339\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/13a57f2ae70e538b15a7e8959e48f3bf\n",
      "\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/5df8e97a3f931aa4d6b4f61da5ea5164\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/58c730db57138a80c62b7b53f993bfa5\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/c62c86018d15057657dc95f249f12814\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/ec6725e4cb06d9ba706965589941e55d\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/f3f410c035961c5a323fe8754e89a19c\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/e2942ceb4705e7953793d3dc8beb7c05\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/df64532ed1535c202da110b5a85be1b5\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/f209cb2abdf723b54af41e5bca289faf\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/9ddbcde634dda45085cc6752b4fee960\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/1e66277707ca987941a577a8a0bcdbb9\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/d0853a8dcb8b3babe509574dd50c5289[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/6d93f3caea1139538e89718283563d4f\n",
      "\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/56ac55a114643c91e20d037654c16e40\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/f7f52266defac6184b32427adfce12cd\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/63a0ab36d75c03c23365a5f4affd844e\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/2a771d0e2b063a4aeff3d93f0215795f\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/7d18769eff80689036372adb75cacb25\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/34d3a57bcec2d49b38964163c38a7eff\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/deec60849ad54c93afcfe38942107728\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/a7e55b4c089e6bd059116c70d9a24101\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/93946672fecbd082813604f7dc417e60\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/1663484bfd6bd60e2688d0f2670083f7\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/45f06e1099bfc878009a96633eef79d6\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/8045735c1545064594a5b0fbf0653527\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/53f5085a103577bd29211ce9a69e73f1\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/bcc6919ff3854583af627c4a818c77d2\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/12b453999c78c6bed0ad26ff20786342\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/72bf08ee7ee156f5b7c11b61e812edb3\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/c4fe1077afe54d0e7a8bc9866510d924\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/3d4ac0140f0239803478aa682020a5c9\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/a50c953e631260971dd8690972e683a7[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/fa1e2d3da009c18f0ecfd4b5f7b1f53e\n",
      "\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/d2a1c1f71fd1c50b2a5d7ed763afa22e\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/a8358ae19ab37b727942d8d4759f082f\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/727cfb98f0cdc2d68f065ab67f167b32\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/8bff1bcd2db8c46a9d41332f506e2bdd\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/eebc4bfc354f85458777a9dca2070d65\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/12d3cebbcbb470d010ab5a091f6b6395\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/7aafface3666fa24d5d007289da33a67\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/52fb06d2507994ba9cf839f02d40f2ae\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/bc4a30790fb99bc79172a4452fc7a2a9\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/e8208fbd700afc1bb160cd1780b59b31\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/a5416a2b109f06f8fbc3dc601fb101cf\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/0c48b50b33c99f6f36c4d628524f50d5\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/b736eedfe639c2724c80a1cdb2475f18\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/5e7d35b2b71a646d26fe6cafdf378d94[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/35141b0fb0f0ece717342bf4832dac87\n",
      "\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/72af6ccaf3b6c05985a09cc0123c5500\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/ab29dbdd526a90f59e699ae8df95bb21\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/c65341ee8f01d049251bed0ffd76e762\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/4e15e7833dbd2f4d795764af6b78b4cb\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/bc7d3b4119598dee1312c57a0061cc82\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/7913dbbcd3c81a2b92b258c2e1d21238\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/1ada1454972d8fb16adf9af6222540b6\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/08a060b7e846621c9900b891985c70f2\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/2b2afb8c6787b53f24f95239cb61242e\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/81c594341f8f87b7ad9ef7c14afa1003\n",
      "[Memory]: Loading calculate_score_from_weaving_config from cache/joblib/llm_weaver/calculate_score_from_weaving_config/d5f4f6aa2ef0580713abf31a4fbc1643\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n",
      "_________________calculate_score_from_weaving_config cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies, weave_configs = sample_config_to_plots(\n",
    "    dict(p=0.5, seed=42, max_configs=100),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the models that did so well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.740072202166065\n",
      "{'blank_model_config': {'add_cross_attention': False,\n",
      "                        'architectures': ['RobertaForSequenceClassification'],\n",
      "                        'attention_probs_dropout_prob': 0.1,\n",
      "                        'bad_words_ids': None,\n",
      "                        'begin_suppress_tokens': None,\n",
      "                        'bos_token_id': 0,\n",
      "                        'chunk_size_feed_forward': 0,\n",
      "                        'classifier_dropout': None,\n",
      "                        'cross_attention_hidden_size': None,\n",
      "                        'decoder_start_token_id': None,\n",
      "                        'diversity_penalty': 0.0,\n",
      "                        'do_sample': False,\n",
      "                        'early_stopping': False,\n",
      "                        'encoder_no_repeat_ngram_size': 0,\n",
      "                        'eos_token_id': 2,\n",
      "                        'exponential_decay_length_penalty': None,\n",
      "                        'finetuning_task': 'glue:rte',\n",
      "                        'forced_bos_token_id': None,\n",
      "                        'forced_eos_token_id': None,\n",
      "                        'gradient_checkpointing': False,\n",
      "                        'hidden_act': 'gelu',\n",
      "                        'hidden_dropout_prob': 0.1,\n",
      "                        'hidden_size': 768,\n",
      "                        'id2label': {0: 'LABEL_0', 1: 'LABEL_1'},\n",
      "                        'initializer_range': 0.02,\n",
      "                        'intermediate_size': 3072,\n",
      "                        'is_decoder': False,\n",
      "                        'is_encoder_decoder': False,\n",
      "                        'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n",
      "                        'layer_norm_eps': 1e-05,\n",
      "                        'length_penalty': 1.0,\n",
      "                        'max_length': 20,\n",
      "                        'max_position_embeddings': 514,\n",
      "                        'min_length': 0,\n",
      "                        'model_type': 'roberta',\n",
      "                        'no_repeat_ngram_size': 0,\n",
      "                        'num_attention_heads': 12,\n",
      "                        'num_beam_groups': 1,\n",
      "                        'num_beams': 1,\n",
      "                        'num_hidden_layers': 12,\n",
      "                        'num_return_sequences': 1,\n",
      "                        'output_attentions': False,\n",
      "                        'output_hidden_states': False,\n",
      "                        'output_scores': False,\n",
      "                        'pad_token_id': 1,\n",
      "                        'position_embedding_type': 'absolute',\n",
      "                        'prefix': None,\n",
      "                        'problem_type': None,\n",
      "                        'pruned_heads': {},\n",
      "                        'remove_invalid_values': False,\n",
      "                        'repetition_penalty': 1.0,\n",
      "                        'return_dict': True,\n",
      "                        'return_dict_in_generate': False,\n",
      "                        'sep_token_id': None,\n",
      "                        'suppress_tokens': None,\n",
      "                        'task_specific_params': None,\n",
      "                        'temperature': 1.0,\n",
      "                        'tf_legacy_loss': False,\n",
      "                        'tie_encoder_decoder': False,\n",
      "                        'tie_word_embeddings': True,\n",
      "                        'tokenizer_class': None,\n",
      "                        'top_k': 50,\n",
      "                        'top_p': 1.0,\n",
      "                        'torch_dtype': None,\n",
      "                        'torchscript': False,\n",
      "                        'transformers_version': '4.35.0',\n",
      "                        'type_vocab_size': 1,\n",
      "                        'typical_p': 1.0,\n",
      "                        'use_bfloat16': False,\n",
      "                        'use_cache': True,\n",
      "                        'vocab_size': 50265},\n",
      " 'classification_head': {'params': {'donor': 'textattack/roberta-base-RTE'},\n",
      "                         'type': 'SingleClassificationHead'},\n",
      " 'embeddings': {'params': {'donor': 'textattack/roberta-base-RTE'},\n",
      "                'type': 'SingleEmbeddings'},\n",
      " 'glue_task': 'rte',\n",
      " 'layer_assignments': [{'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 0},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-MNLI',\n",
      "                                   'hidden_layer_number': 1},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 2},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 3},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-MNLI',\n",
      "                                   'hidden_layer_number': 4},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 5},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 6},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 7},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 8},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 9},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 10},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 11},\n",
      "                        'type': 'SingleLayer'}],\n",
      " 'tokenizer_model_id': 'textattack/roberta-base-RTE'}\n"
     ]
    }
   ],
   "source": [
    "# Get max accuracy index\n",
    "max_accuracy_index = accuracies.index(max(accuracies))\n",
    "# accuracies\n",
    "\n",
    "# Get the best config/\n",
    "best_config = weave_configs[max_accuracy_index]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(max(accuracies))\n",
    "pprint(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-MNLI', 'hidden_layer_number': 1},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-MNLI', 'hidden_layer_number': 4},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11},\n",
      "  'type': 'SingleLayer'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(best_config['layer_assignments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating one Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to sample configs\n",
    "import random\n",
    "\n",
    "from llm_weaver import dict_overwrite, get_model_config\n",
    "\n",
    "\n",
    "def sample_weave_configs_iter_layers(p=0.5, seed=42, max_configs=1):\n",
    "\n",
    "    donor_model_ids = [\n",
    "        \"textattack/roberta-base-RTE\",\n",
    "        \"textattack/roberta-base-RTE\",\n",
    "    ]\n",
    "    blank_model_config = dict_overwrite(\n",
    "        get_model_config(\"textattack/roberta-base-RTE\"),\n",
    "        {\n",
    "            \"num_hidden_layers\": 13 ,\n",
    "        },\n",
    "    )\n",
    "    num_hidden_layers = 13\n",
    "    layers_to_repeat = [i for i in range(num_hidden_layers-1)]\n",
    "    print(layers_to_repeat)\n",
    "    \n",
    "    for config_index in range(max_configs):\n",
    "        repeat_layer = layers_to_repeat[config_index]\n",
    "        # repeat_layer = 0\n",
    "        layer_assignments = []\n",
    "        for i in range(num_hidden_layers-1):\n",
    "            layer_assignment = {\n",
    "                \"type\": \"SingleLayer\",\n",
    "                \"params\": {\n",
    "                    \"donor\": random.choices(donor_model_ids, weights=[p, 1 - p])[0],\n",
    "                    \"hidden_layer_number\": i,\n",
    "                },\n",
    "            }\n",
    "            layer_assignments.append(layer_assignment)\n",
    "            \n",
    "            print(layer_assignment)\n",
    "\n",
    "            # Repeat the selected layer\n",
    "            if i == repeat_layer:\n",
    "                # print(i) \n",
    "                layer_assignment = {\n",
    "                    \"type\": \"SingleLayer\",\n",
    "                    \"params\": {\n",
    "                        \"donor\": random.choices(donor_model_ids, weights=[p, 1 - p])[0],\n",
    "                        \"hidden_layer_number\": i,\n",
    "                        },\n",
    "                    }\n",
    "                print(layer_assignment)\n",
    "                layer_assignments.append(layer_assignment)\n",
    "        print(len(layer_assignments))\n",
    "        config = {\n",
    "            \"glue_task\": \"rte\",\n",
    "            \"tokenizer_model_id\": \"textattack/roberta-base-RTE\",\n",
    "            \"blank_model_config\": blank_model_config,\n",
    "            \"layer_assignments\": layer_assignments,\n",
    "            \"classification_head\": {\n",
    "                \"type\": \"SingleClassificationHead\",\n",
    "                \"params\": {\n",
    "                    \"donor\": \"textattack/roberta-base-RTE\",\n",
    "                },\n",
    "            },\n",
    "            \"embeddings\": {\n",
    "                \"type\": \"SingleEmbeddings\",\n",
    "                \"params\": {\n",
    "                    \"donor\": \"textattack/roberta-base-RTE\",\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        yield config  \n",
    "\n",
    "\n",
    "sample_config = dict(p=0.5, seed=42, max_configs=12)\n",
    "\n",
    "# Generate the sample configs and save to a file just in case\n",
    "weave_configs = list(sample_weave_configs_iter_layers(**sample_config))\n",
    "\n",
    "\n",
    "len(weave_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}\n",
      "13\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: b50e692e65f48ce3edcebb9d68004014\n",
      "calculating score for weaving config md5sum: 3587157e55768b8d2599842548f65e89\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')calculating score for weaving config md5sum: 22e90033d999011607f9da3d5e59f267\n",
      "\n",
      "calculating score for weaving config md5sum: 501704881db9c32d4580654de4f88e46\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 11c6c1fe841aa6b73f5fbedaec5ba270\n",
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 63.6s, 1.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 2e238fe2d4ab45839015f38c00fbdb2e\n",
      "_____________________________calculate_score_from_weaving_config - 66.0s, 1.1min\n",
      "_____________________________calculate_score_from_weaving_config - 66.1s, 1.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: a0f307387120ab78006d468d2a5a4bc8\n",
      "Loading textattack/roberta-base-RTE\n",
      "_____________________________calculate_score_from_weaving_config - 66.4s, 1.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 4b8673bbaadfb7798c2fcb57c7153cc4\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: e99d1a4aef1c26887af21080ab1136b7\n",
      "_____________________________calculate_score_from_weaving_config - 67.2s, 1.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: f9faebe16ec38f2c67b5df22277ce401\n",
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 59.8s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 90e9046d5284ab17fd524be314af3b65\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 63.0s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 1dee758010d8d8f226a1ebc08e6a0f17\n",
      "_____________________________calculate_score_from_weaving_config - 63.8s, 1.1min\n",
      "_____________________________calculate_score_from_weaving_config - 64.1s, 1.1min\n",
      "_____________________________calculate_score_from_weaving_config - 63.7s, 1.1min\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 32.4s, 0.5min\n",
      "_____________________________calculate_score_from_weaving_config - 29.5s, 0.5min\n",
      "[0.6028880866425993, 0.6101083032490975, 0.6678700361010831, 0.6967509025270758, 0.6895306859205776, 0.6859205776173285, 0.703971119133574, 0.7364620938628159, 0.7148014440433214, 0.7292418772563177, 0.7184115523465704, 0.7256317689530686]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracies = []\n",
    "\n",
    "def sample_config_to_plots(sample_config, n_jobs=5):\n",
    "    weave_configs = list(\n",
    "        sample_weave_configs_iter_layers(**sample_config),\n",
    "    )\n",
    "    # for config in weave_configs:\n",
    "        \n",
    "    #     print(config['layer_assignments'])\n",
    "    scores = Parallel(n_jobs=n_jobs, return_as=\"list\")(\n",
    "        delayed(calculate_score_from_weaving_config_cached)(\n",
    "            weave_config,\n",
    "            n_examples=4096,\n",
    "            split=\"validation\",\n",
    "        )\n",
    "        for weave_config in weave_configs\n",
    "    )\n",
    "    accuracies = [score[\"accuracy\"] for score in scores]\n",
    "    print(accuracies)\n",
    "\n",
    "    title = f\"Accuracy distribution on task {weave_configs[0]['glue_task']} with p={sample_config['p']} with N={len(accuracies)}\"\n",
    "\n",
    "    # create figure and ax\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(accuracies, bins=10)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return accuracies, weave_configs\n",
    "\n",
    "\n",
    "accuracies, weave_configs = sample_config_to_plots(\n",
    "    dict(p=0.5, seed=42, max_configs=12),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7364620938628159\n",
      "{'blank_model_config': {'add_cross_attention': False,\n",
      "                        'architectures': ['RobertaForSequenceClassification'],\n",
      "                        'attention_probs_dropout_prob': 0.1,\n",
      "                        'bad_words_ids': None,\n",
      "                        'begin_suppress_tokens': None,\n",
      "                        'bos_token_id': 0,\n",
      "                        'chunk_size_feed_forward': 0,\n",
      "                        'classifier_dropout': None,\n",
      "                        'cross_attention_hidden_size': None,\n",
      "                        'decoder_start_token_id': None,\n",
      "                        'diversity_penalty': 0.0,\n",
      "                        'do_sample': False,\n",
      "                        'early_stopping': False,\n",
      "                        'encoder_no_repeat_ngram_size': 0,\n",
      "                        'eos_token_id': 2,\n",
      "                        'exponential_decay_length_penalty': None,\n",
      "                        'finetuning_task': 'glue:rte',\n",
      "                        'forced_bos_token_id': None,\n",
      "                        'forced_eos_token_id': None,\n",
      "                        'gradient_checkpointing': False,\n",
      "                        'hidden_act': 'gelu',\n",
      "                        'hidden_dropout_prob': 0.1,\n",
      "                        'hidden_size': 768,\n",
      "                        'id2label': {0: 'LABEL_0', 1: 'LABEL_1'},\n",
      "                        'initializer_range': 0.02,\n",
      "                        'intermediate_size': 3072,\n",
      "                        'is_decoder': False,\n",
      "                        'is_encoder_decoder': False,\n",
      "                        'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n",
      "                        'layer_norm_eps': 1e-05,\n",
      "                        'length_penalty': 1.0,\n",
      "                        'max_length': 20,\n",
      "                        'max_position_embeddings': 514,\n",
      "                        'min_length': 0,\n",
      "                        'model_type': 'roberta',\n",
      "                        'no_repeat_ngram_size': 0,\n",
      "                        'num_attention_heads': 12,\n",
      "                        'num_beam_groups': 1,\n",
      "                        'num_beams': 1,\n",
      "                        'num_hidden_layers': 13,\n",
      "                        'num_return_sequences': 1,\n",
      "                        'output_attentions': False,\n",
      "                        'output_hidden_states': False,\n",
      "                        'output_scores': False,\n",
      "                        'pad_token_id': 1,\n",
      "                        'position_embedding_type': 'absolute',\n",
      "                        'prefix': None,\n",
      "                        'problem_type': None,\n",
      "                        'pruned_heads': {},\n",
      "                        'remove_invalid_values': False,\n",
      "                        'repetition_penalty': 1.0,\n",
      "                        'return_dict': True,\n",
      "                        'return_dict_in_generate': False,\n",
      "                        'sep_token_id': None,\n",
      "                        'suppress_tokens': None,\n",
      "                        'task_specific_params': None,\n",
      "                        'temperature': 1.0,\n",
      "                        'tf_legacy_loss': False,\n",
      "                        'tie_encoder_decoder': False,\n",
      "                        'tie_word_embeddings': True,\n",
      "                        'tokenizer_class': None,\n",
      "                        'top_k': 50,\n",
      "                        'top_p': 1.0,\n",
      "                        'torch_dtype': None,\n",
      "                        'torchscript': False,\n",
      "                        'transformers_version': '4.35.0',\n",
      "                        'type_vocab_size': 1,\n",
      "                        'typical_p': 1.0,\n",
      "                        'use_bfloat16': False,\n",
      "                        'use_cache': True,\n",
      "                        'vocab_size': 50265},\n",
      " 'classification_head': {'params': {'donor': 'textattack/roberta-base-RTE'},\n",
      "                         'type': 'SingleClassificationHead'},\n",
      " 'embeddings': {'params': {'donor': 'textattack/roberta-base-RTE'},\n",
      "                'type': 'SingleEmbeddings'},\n",
      " 'glue_task': 'rte',\n",
      " 'layer_assignments': [{'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 0},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 1},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 2},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 3},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 4},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 5},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 6},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 7},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 7},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 8},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 9},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 10},\n",
      "                        'type': 'SingleLayer'},\n",
      "                       {'params': {'donor': 'textattack/roberta-base-RTE',\n",
      "                                   'hidden_layer_number': 11},\n",
      "                        'type': 'SingleLayer'}],\n",
      " 'tokenizer_model_id': 'textattack/roberta-base-RTE'}\n"
     ]
    }
   ],
   "source": [
    "# Get max accuracy index\n",
    "max_accuracy_index = accuracies.index(max(accuracies))\n",
    "# accuracies\n",
    "\n",
    "# Get the best config\n",
    "best_config = weave_configs[max_accuracy_index]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(max(accuracies))\n",
    "pprint(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11},\n",
      "  'type': 'SingleLayer'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(best_config['layer_assignments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipping a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}]\n"
     ]
    }
   ],
   "source": [
    "# Function to sample configs\n",
    "import random\n",
    "\n",
    "from llm_weaver import dict_overwrite, get_model_config\n",
    "\n",
    "\n",
    "def sample_weave_configs_iter_layers(p=0.5, seed=42, max_configs=1):\n",
    "\n",
    "    donor_model_ids = [\n",
    "        \"textattack/roberta-base-RTE\",\n",
    "        # \"textattack/roberta-base-MNLI\",\n",
    "        \"textattack/roberta-base-RTE\",\n",
    "    ]\n",
    "    blank_model_config = dict_overwrite(\n",
    "        get_model_config(\"textattack/roberta-base-RTE\"),\n",
    "        {\n",
    "            \"num_hidden_layers\": 11,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    skip_layer = 0  # Initialize skip_layer variable\n",
    "\n",
    "    for _ in range(max_configs):\n",
    "        # print(skip_layer)\n",
    "        config = {\n",
    "            \"glue_task\": \"rte\",\n",
    "            \"tokenizer_model_id\": \"textattack/roberta-base-RTE\",\n",
    "            \"blank_model_config\": blank_model_config,\n",
    "            \"layer_assignments\": [\n",
    "                {\n",
    "                    \"type\": \"SingleLayer\",\n",
    "                    \"params\": {\n",
    "                        \"donor\": random.choices(donor_model_ids, weights=[p, 1 - p])[0],\n",
    "                        \"hidden_layer_number\": i,\n",
    "                    },\n",
    "                }\n",
    "                for i in range(12) if i != skip_layer \n",
    "            ],\n",
    "            \"classification_head\": {\n",
    "                \"type\": \"SingleClassificationHead\",\n",
    "                \"params\": {\n",
    "                    \"donor\": \"textattack/roberta-base-RTE\",\n",
    "                },\n",
    "            },\n",
    "            \"embeddings\": {\n",
    "                \"type\": \"SingleEmbeddings\",\n",
    "                \"params\": {\n",
    "                    \"donor\": \"textattack/roberta-base-RTE\",\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        print(config['layer_assignments'])\n",
    "        # print(len(config['layer_assignments']))\n",
    "        yield config\n",
    "        skip_layer = (skip_layer + 1) % 12  # Increment skip_layer for the next configuration\n",
    "\n",
    "\n",
    "\n",
    "sample_config = dict(p=0.5, seed=42, max_configs=12)\n",
    "# Generate the sample configs and save to a file just in case\n",
    "weave_configs = list(sample_weave_configs_iter_layers(**sample_config))\n",
    "\n",
    "\n",
    "# len(weave_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11}}]\n",
      "[{'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9}}, {'type': 'SingleLayer', 'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 10}}]\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: cb393ab08e2f04f6274653c4c47ba7f0\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 9cb5a8967322f9cadf367925867b74a4\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 7cb26921c0cfc6e8d01602e3c5cb6579\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: c142f6522fa4568e30a5072b584f4369\n",
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 84d6896def8fd22cb36b34cf37826f0e\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/model_merging/model_merging/evaluation.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  return hfds.load_metric(\"glue\", task)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 77.9s, 1.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 6fa778605270c5cde92202256b1bc51b\n",
      "_____________________________calculate_score_from_weaving_config - 78.5s, 1.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 41e17d5e49182ad42a7ee73ca48aea8d\n",
      "_____________________________calculate_score_from_weaving_config - 80.7s, 1.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 6e6efb0fe28fd5727287c572cba58663\n",
      "Loading textattack/roberta-base-RTE\n",
      "_____________________________calculate_score_from_weaving_config - 83.2s, 1.4min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 8eeaeecdcf51cc30199a68d76ae750bc\n",
      "Loading textattack/roberta-base-RTE\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 87.4s, 1.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 726df71195e9562a3b57d5445258e379\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 88.4s, 1.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 10e152410e51ce542c31ad76676d4211\n",
      "_____________________________calculate_score_from_weaving_config - 90.3s, 1.5min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling llm_weaver.calculate_score_from_weaving_config...\n",
      "calculate_score_from_weaving_config({ 'blank_model_config': { 'add_cross_attention': False,\n",
      "                          'architectures': ['RobertaForSequenceClassification'],\n",
      "                          'attention_probs_dropout_prob': 0.1,\n",
      "                          'bad_words_ids': None,\n",
      "                          'begin_suppress_tokens': None,\n",
      "                          'bos_token_id': 0,\n",
      "                          'chunk_size_feed_forward': 0,\n",
      "                          'classifier_dropout': None,\n",
      "                          'cross_attention_hidden_size': None,\n",
      "                          'decoder_start_token_id': None,\n",
      "                          'diversity_penalty': 0.0,\n",
      "                          'do_sample': False,\n",
      "                    ..., n_examples=4096, split='validation')\n",
      "calculating score for weaving config md5sum: 600e4920e3b772b0e7a69053ccfa1085\n",
      "WARNING: All predictions are the same! Is your model broken? [1]\n",
      "_____________________________calculate_score_from_weaving_config - 88.9s, 1.5min\n",
      "Loading textattack/roberta-base-RTE\n",
      "_____________________________calculate_score_from_weaving_config - 88.3s, 1.5min\n",
      "Loading textattack/roberta-base-RTE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "/Users/hivamoh/Desktop/CS194/2023-fall-cs-194-294-merging-llms/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:520: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________calculate_score_from_weaving_config - 87.2s, 1.5min\n",
      "_____________________________calculate_score_from_weaving_config - 43.1s, 0.7min\n",
      "_____________________________calculate_score_from_weaving_config - 41.7s, 0.7min\n",
      "[0.5090252707581228, 0.5884476534296029, 0.5523465703971119, 0.5379061371841155, 0.5992779783393501, 0.51985559566787, 0.5342960288808665, 0.47653429602888087, 0.555956678700361, 0.6498194945848376, 0.7075812274368231, 0.628158844765343]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sample_config_to_plots(sample_config, n_jobs=5):\n",
    "    accuracies = []\n",
    "    weave_configs = list(\n",
    "        sample_weave_configs_iter_layers(**sample_config),\n",
    "    )\n",
    "    # for config in weave_configs:\n",
    "        \n",
    "    #     # print(config['layer_assignments'])\n",
    "    scores = Parallel(n_jobs=n_jobs, return_as=\"list\")(\n",
    "        delayed(calculate_score_from_weaving_config_cached)(\n",
    "            weave_config,\n",
    "            n_examples=4096,\n",
    "            split=\"validation\",\n",
    "        )\n",
    "        for weave_config in weave_configs\n",
    "    )\n",
    "    accuracies = [score[\"accuracy\"] for score in scores]\n",
    "    print(accuracies)\n",
    "\n",
    "    title = f\"Accuracy distribution on task {weave_configs[0]['glue_task']} with p={sample_config['p']} with N={len(accuracies)}\"\n",
    "\n",
    "    # create figure and ax\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(accuracies, bins=10)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return accuracies, weave_configs\n",
    "\n",
    "\n",
    "accuracies, weave_configs = sample_config_to_plots(\n",
    "    dict(p=0.5, seed=42, max_configs=12),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7075812274368231\n",
      "[{'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 0},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 1},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 2},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 3},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 4},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 5},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 6},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 7},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 8},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 9},\n",
      "  'type': 'SingleLayer'},\n",
      " {'params': {'donor': 'textattack/roberta-base-RTE', 'hidden_layer_number': 11},\n",
      "  'type': 'SingleLayer'}]\n"
     ]
    }
   ],
   "source": [
    "# Get max accuracy index\n",
    "max_accuracy_index = accuracies.index(max(accuracies))\n",
    "# accuracies\n",
    "\n",
    "# Get the best config\n",
    "best_config = weave_configs[max_accuracy_index]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(max(accuracies))\n",
    "# pprint(best_config)\n",
    "pprint(best_config['layer_assignments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(0, x+1) + range(y, num_hidden_layers) \n",
    "x in range(12)\n",
    "y in range(12)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "418d7ffbf17f07fb7db812548652bd547b7709e294d6b5c17ab307303352fd7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
